{"ast":null,"code":"/**\n * @module ol/renderer/webgl/PointsLayer\n */\nimport BaseVector from '../../layer/BaseVector.js';\nimport VectorEventType from '../../source/VectorEventType.js';\nimport ViewHint from '../../ViewHint.js';\nimport WebGLArrayBuffer from '../../webgl/Buffer.js';\nimport WebGLLayerRenderer from './Layer.js';\nimport WebGLRenderTarget from '../../webgl/RenderTarget.js';\nimport { ARRAY_BUFFER, DYNAMIC_DRAW, ELEMENT_ARRAY_BUFFER } from '../../webgl.js';\nimport { AttributeType, DefaultUniform } from '../../webgl/Helper.js';\nimport { WebGLWorkerMessageType } from '../../render/webgl/constants.js';\nimport { apply as applyTransform, create as createTransform, makeInverse as makeInverseTransform, multiply as multiplyTransform, translate as translateTransform } from '../../transform.js';\nimport { assert } from '../../asserts.js';\nimport { buffer, createEmpty, equals } from '../../extent.js';\nimport { colorDecodeId, colorEncodeId } from '../../render/webgl/utils.js';\nimport { create as createWebGLWorker } from '../../worker/webgl.js';\nimport { fromUserCoordinate, getUserProjection } from '../../proj.js';\nimport { getUid } from '../../util.js';\nimport { getWorldParameters } from './worldUtil.js';\nimport { listen, unlistenByKey } from '../../events.js';\n\n/**\n * @typedef {Object} CustomAttribute A description of a custom attribute to be passed on to the GPU, with a value different\n * for each feature.\n * @property {string} name Attribute name.\n * @property {function(import(\"../../Feature\").default, Object<string, *>):number} callback This callback computes the numerical value of the\n * attribute for a given feature (properties are available as 2nd arg for quicker access).\n */\n\n/**\n * @typedef {Object} FeatureCacheItem Object that holds a reference to a feature, its geometry and properties. Used to optimize\n * rebuildBuffers by accessing these objects quicker.\n * @property {import(\"../../Feature\").default} feature Feature\n * @property {Object<string, *>} properties Feature properties\n * @property {import(\"../../geom\").Geometry} geometry Feature geometry\n */\n\n/**\n * @typedef {Object} Options\n * @property {string} [className='ol-layer'] A CSS class name to set to the canvas element.\n * @property {Array<CustomAttribute>} [attributes] These attributes will be read from the features in the source and then\n * passed to the GPU. The `name` property of each attribute will serve as its identifier:\n *  * In the vertex shader as an `attribute` by prefixing it with `a_`\n *  * In the fragment shader as a `varying` by prefixing it with `v_`\n * Please note that these can only be numerical values.\n * @property {string} vertexShader Vertex shader source, mandatory.\n * @property {string} fragmentShader Fragment shader source, mandatory.\n * @property {boolean} [hitDetectionEnabled] Whether shader is hit detection aware.\n * @property {Object<string,import(\"../../webgl/Helper\").UniformValue>} [uniforms] Uniform definitions for the post process steps\n * Please note that `u_texture` is reserved for the main texture slot and `u_opacity` is reserved for the layer opacity.\n * @property {Array<import(\"./Layer\").PostProcessesOptions>} [postProcesses] Post-processes definitions\n */\n\n/**\n * @classdesc\n * WebGL vector renderer optimized for points.\n * All features will be rendered as quads (two triangles forming a square). New data will be flushed to the GPU\n * every time the vector source changes.\n *\n * You need to provide vertex and fragment shaders for rendering. This can be done using\n * {@link module:ol/webgl/ShaderBuilder~ShaderBuilder} utilities. These shaders shall expect a `a_position` attribute\n * containing the screen-space projected center of the quad, as well as a `a_index` attribute\n * whose value (0, 1, 2 or 3) indicates which quad vertex is currently getting processed (see structure below).\n *\n * To include variable attributes in the shaders, you need to declare them using the `attributes` property of\n * the options object like so:\n * ```js\n * new WebGLPointsLayerRenderer(layer, {\n *   attributes: [\n *     {\n *       name: 'size',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *     {\n *       name: 'weight',\n *       callback: function(feature) {\n *         // compute something with the feature\n *       }\n *     },\n *   ],\n *   vertexShader:\n *     // shader using attribute a_weight and a_size\n *   fragmentShader:\n *     // shader using varying v_weight and v_size\n * ```\n *\n * To enable hit detection, you must as well provide dedicated shaders using the `hitVertexShader`\n * and `hitFragmentShader` properties. These shall expect the `a_hitColor` attribute to contain\n * the final color that will have to be output for hit detection to work.\n *\n * The following uniform is used for the main texture: `u_texture`.\n * The following uniform is used for the layer opacity: `u_opacity`.\n *\n * Please note that the main shader output should have premultiplied alpha, otherwise visual anomalies may occur.\n *\n * Points are rendered as quads with the following structure:\n *\n * ```\n *   (u0, v1)      (u1, v1)\n *  [3]----------[2]\n *   |`           |\n *   |  `         |\n *   |    `       |\n *   |      `     |\n *   |        `   |\n *   |          ` |\n *  [0]----------[1]\n *   (u0, v0)      (u1, v0)\n *  ```\n *\n * This uses {@link module:ol/webgl/Helper~WebGLHelper} internally.\n *\n * @api\n */\nclass WebGLPointsLayerRenderer extends WebGLLayerRenderer {\n  /**\n   * @param {import(\"../../layer/Layer.js\").default} layer Layer.\n   * @param {Options} options Options.\n   */\n  constructor(layer, options) {\n    const uniforms = options.uniforms || {};\n    const projectionMatrixTransform = createTransform();\n    uniforms[DefaultUniform.PROJECTION_MATRIX] = projectionMatrixTransform;\n    super(layer, {\n      uniforms: uniforms,\n      postProcesses: options.postProcesses\n    });\n    this.sourceRevision_ = -1;\n    this.verticesBuffer_ = new WebGLArrayBuffer(ARRAY_BUFFER, DYNAMIC_DRAW);\n    this.indicesBuffer_ = new WebGLArrayBuffer(ELEMENT_ARRAY_BUFFER, DYNAMIC_DRAW);\n\n    /**\n     * @private\n     */\n    this.vertexShader_ = options.vertexShader;\n\n    /**\n     * @private\n     */\n    this.fragmentShader_ = options.fragmentShader;\n\n    /**\n     * @type {WebGLProgram}\n     * @private\n     */\n    this.program_;\n\n    /**\n     * @type {boolean}\n     * @private\n     */\n    this.hitDetectionEnabled_ = options.hitDetectionEnabled ?? true;\n    const customAttributes = options.attributes ? options.attributes.map(function (attribute) {\n      return {\n        name: 'a_prop_' + attribute.name,\n        size: 1,\n        type: AttributeType.FLOAT\n      };\n    }) : [];\n\n    /**\n     * A list of attributes used by the renderer. By default only the position and\n     * index of the vertex (0 to 3) are required.\n     * @type {Array<import('../../webgl/Helper.js').AttributeDescription>}\n     */\n    this.attributes = [{\n      name: 'a_position',\n      size: 2,\n      type: AttributeType.FLOAT\n    }, {\n      name: 'a_index',\n      size: 1,\n      type: AttributeType.FLOAT\n    }];\n    if (this.hitDetectionEnabled_) {\n      this.attributes.push({\n        name: 'a_prop_hitColor',\n        size: 4,\n        type: AttributeType.FLOAT\n      });\n      this.attributes.push({\n        name: 'a_featureUid',\n        size: 1,\n        type: AttributeType.FLOAT\n      });\n    }\n    this.attributes.push(...customAttributes);\n    this.customAttributes = options.attributes ? options.attributes : [];\n    this.previousExtent_ = createEmpty();\n\n    /**\n     * This transform is updated on every frame and is the composition of:\n     * - invert of the world->screen transform that was used when rebuilding buffers (see `this.renderTransform_`)\n     * - current world->screen transform\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    this.currentTransform_ = projectionMatrixTransform;\n\n    /**\n     * This transform is updated when buffers are rebuilt and converts world space coordinates to screen space\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    this.renderTransform_ = createTransform();\n\n    /**\n     * @type {import(\"../../transform.js\").Transform}\n     * @private\n     */\n    this.invertRenderTransform_ = createTransform();\n\n    /**\n     * @type {Float32Array}\n     * @private\n     */\n    this.renderInstructions_ = new Float32Array(0);\n\n    /**\n     * @type {WebGLRenderTarget}\n     * @private\n     */\n    this.hitRenderTarget_;\n\n    /**\n     * Keep track of latest message sent to worker\n     * @type {number}\n     * @private\n     */\n    this.lastSentId = 0;\n\n    /**\n     * @private\n     */\n    this.worker_ = createWebGLWorker();\n    this.worker_.addEventListener('message',\n    /**\n     * @param {*} event Event.\n     */\n    event => {\n      const received = event.data;\n      if (received.type === WebGLWorkerMessageType.GENERATE_POINT_BUFFERS) {\n        const projectionTransform = received.projectionTransform;\n        this.verticesBuffer_.fromArrayBuffer(received.vertexBuffer);\n        this.helper.flushBufferData(this.verticesBuffer_);\n        this.indicesBuffer_.fromArrayBuffer(received.indexBuffer);\n        this.helper.flushBufferData(this.indicesBuffer_);\n        this.renderTransform_ = projectionTransform;\n        makeInverseTransform(this.invertRenderTransform_, this.renderTransform_);\n        this.renderInstructions_ = new Float32Array(event.data.renderInstructions);\n        if (received.id === this.lastSentId) {\n          this.ready = true;\n        }\n        this.getLayer().changed();\n      }\n    });\n\n    /**\n     * This object will be updated when the source changes. Key is uid.\n     * @type {Object<string, FeatureCacheItem>}\n     * @private\n     */\n    this.featureCache_ = {};\n\n    /**\n     * Amount of features in the cache.\n     * @type {number}\n     * @private\n     */\n    this.featureCount_ = 0;\n    const source = this.getLayer().getSource();\n    this.sourceListenKeys_ = [listen(source, VectorEventType.ADDFEATURE, this.handleSourceFeatureAdded_, this), listen(source, VectorEventType.CHANGEFEATURE, this.handleSourceFeatureChanged_, this), listen(source, VectorEventType.REMOVEFEATURE, this.handleSourceFeatureDelete_, this), listen(source, VectorEventType.CLEAR, this.handleSourceFeatureClear_, this)];\n    source.forEachFeature(feature => {\n      this.featureCache_[getUid(feature)] = {\n        feature: feature,\n        properties: feature.getProperties(),\n        geometry: feature.getGeometry()\n      };\n      this.featureCount_++;\n    });\n  }\n  afterHelperCreated() {\n    this.program_ = this.helper.getProgram(this.fragmentShader_, this.vertexShader_);\n    if (this.hitDetectionEnabled_) {\n      this.hitRenderTarget_ = new WebGLRenderTarget(this.helper);\n    }\n  }\n\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  handleSourceFeatureAdded_(event) {\n    const feature = event.feature;\n    this.featureCache_[getUid(feature)] = {\n      feature: feature,\n      properties: feature.getProperties(),\n      geometry: feature.getGeometry()\n    };\n    this.featureCount_++;\n  }\n\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  handleSourceFeatureChanged_(event) {\n    const feature = event.feature;\n    this.featureCache_[getUid(feature)] = {\n      feature: feature,\n      properties: feature.getProperties(),\n      geometry: feature.getGeometry()\n    };\n  }\n\n  /**\n   * @param {import(\"../../source/Vector.js\").VectorSourceEvent} event Event.\n   * @private\n   */\n  handleSourceFeatureDelete_(event) {\n    const feature = event.feature;\n    delete this.featureCache_[getUid(feature)];\n    this.featureCount_--;\n  }\n\n  /**\n   * @private\n   */\n  handleSourceFeatureClear_() {\n    this.featureCache_ = {};\n    this.featureCount_ = 0;\n  }\n\n  /**\n   * Render the layer.\n   * @param {import(\"../../Map.js\").FrameState} frameState Frame state.\n   * @return {HTMLElement} The rendered element.\n   */\n  renderFrame(frameState) {\n    const gl = this.helper.getGL();\n    this.preRender(gl, frameState);\n    const [startWorld, endWorld, worldWidth] = getWorldParameters(frameState, this.getLayer());\n\n    // draw the normal canvas\n    this.renderWorlds(frameState, false, startWorld, endWorld, worldWidth);\n    this.helper.finalizeDraw(frameState, this.dispatchPreComposeEvent, this.dispatchPostComposeEvent);\n    if (this.hitDetectionEnabled_) {\n      // draw the hit buffer\n      this.renderWorlds(frameState, true, startWorld, endWorld, worldWidth);\n      this.hitRenderTarget_.clearCachedData();\n    }\n    this.postRender(gl, frameState);\n    const canvas = this.helper.getCanvas();\n    return canvas;\n  }\n\n  /**\n   * Determine whether renderFrame should be called.\n   * @param {import(\"../../Map.js\").FrameState} frameState Frame state.\n   * @return {boolean} Layer is ready to be rendered.\n   */\n  prepareFrameInternal(frameState) {\n    const layer = this.getLayer();\n    const vectorSource = layer.getSource();\n    const viewState = frameState.viewState;\n    const viewNotMoving = !frameState.viewHints[ViewHint.ANIMATING] && !frameState.viewHints[ViewHint.INTERACTING];\n    const extentChanged = !equals(this.previousExtent_, frameState.extent);\n    const sourceChanged = this.sourceRevision_ < vectorSource.getRevision();\n    if (sourceChanged) {\n      this.sourceRevision_ = vectorSource.getRevision();\n    }\n    if (viewNotMoving && (extentChanged || sourceChanged)) {\n      const projection = viewState.projection;\n      const resolution = viewState.resolution;\n      const renderBuffer = layer instanceof BaseVector ? layer.getRenderBuffer() : 0;\n      const extent = buffer(frameState.extent, renderBuffer * resolution);\n      vectorSource.loadFeatures(extent, resolution, projection);\n      this.rebuildBuffers_(frameState);\n      this.previousExtent_ = frameState.extent.slice();\n    }\n    this.helper.useProgram(this.program_, frameState);\n    this.helper.prepareDraw(frameState);\n\n    // write new data\n    this.helper.bindBuffer(this.verticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.attributes);\n    return true;\n  }\n\n  /**\n   * Rebuild internal webgl buffers based on current view extent; costly, should not be called too much\n   * @param {import(\"../../Map\").FrameState} frameState Frame state.\n   * @private\n   */\n  rebuildBuffers_(frameState) {\n    // saves the projection transform for the current frame state\n    const projectionTransform = createTransform();\n    this.helper.makeProjectionTransform(frameState, projectionTransform);\n    const userProjection = getUserProjection();\n    const baseInstructionLength = this.hitDetectionEnabled_ ? 7 : 2; // see below\n    const singleInstructionLength = baseInstructionLength + this.customAttributes.length;\n    const totalSize = singleInstructionLength * this.featureCount_;\n    if (!this.renderInstructions_ || this.renderInstructions_.length !== totalSize) {\n      this.renderInstructions_ = new Float32Array(totalSize);\n    }\n\n    // loop on features to fill the buffer\n    let featureCache, geometry;\n    const tmpCoords = [];\n    const tmpColor = [];\n    let idx = -1;\n    for (const featureUid in this.featureCache_) {\n      featureCache = this.featureCache_[featureUid];\n      geometry = /** @type {import(\"../../geom\").Point} */\n      featureCache.geometry;\n      if (!geometry || geometry.getType() !== 'Point') {\n        continue;\n      }\n      if (userProjection) {\n        const userCoords = fromUserCoordinate(geometry.getFlatCoordinates(), frameState.viewState.projection);\n        tmpCoords[0] = userCoords[0];\n        tmpCoords[1] = userCoords[1];\n      } else {\n        tmpCoords[0] = geometry.getFlatCoordinates()[0];\n        tmpCoords[1] = geometry.getFlatCoordinates()[1];\n      }\n      applyTransform(projectionTransform, tmpCoords);\n      this.renderInstructions_[++idx] = tmpCoords[0];\n      this.renderInstructions_[++idx] = tmpCoords[1];\n\n      // for hit detection, the feature uid is saved in the opacity value\n      // and the index of the opacity value is encoded in the color values\n      if (this.hitDetectionEnabled_) {\n        const hitColor = colorEncodeId(idx + 5, tmpColor);\n        this.renderInstructions_[++idx] = hitColor[0];\n        this.renderInstructions_[++idx] = hitColor[1];\n        this.renderInstructions_[++idx] = hitColor[2];\n        this.renderInstructions_[++idx] = hitColor[3];\n        this.renderInstructions_[++idx] = Number(featureUid);\n      }\n\n      // pushing custom attributes\n      for (let j = 0; j < this.customAttributes.length; j++) {\n        const value = this.customAttributes[j].callback(featureCache.feature, featureCache.properties);\n        this.renderInstructions_[++idx] = value;\n      }\n    }\n\n    /** @type {import('../../render/webgl/constants.js').WebGLWorkerGenerateBuffersMessage} */\n    const message = {\n      id: ++this.lastSentId,\n      type: WebGLWorkerMessageType.GENERATE_POINT_BUFFERS,\n      renderInstructions: this.renderInstructions_.buffer,\n      customAttributesSize: singleInstructionLength - 2\n    };\n    // additional properties will be sent back as-is by the worker\n    message['projectionTransform'] = projectionTransform;\n    this.ready = false;\n    this.worker_.postMessage(message, [this.renderInstructions_.buffer]);\n    this.renderInstructions_ = null;\n  }\n\n  /**\n   * @param {import(\"../../coordinate.js\").Coordinate} coordinate Coordinate.\n   * @param {import(\"../../Map.js\").FrameState} frameState Frame state.\n   * @param {number} hitTolerance Hit tolerance in pixels.\n   * @param {import(\"../vector.js\").FeatureCallback<T>} callback Feature callback.\n   * @param {Array<import(\"../Map.js\").HitMatch<T>>} matches The hit detected matches with tolerance.\n   * @return {T|undefined} Callback result.\n   * @template T\n   */\n  forEachFeatureAtCoordinate(coordinate, frameState, hitTolerance, callback, matches) {\n    assert(this.hitDetectionEnabled_, '`forEachFeatureAtCoordinate` cannot be used on a WebGL layer if the hit detection logic has been disabled using the `disableHitDetection: true` option.');\n    if (!this.renderInstructions_ || !this.hitDetectionEnabled_) {\n      return undefined;\n    }\n    const pixel = applyTransform(frameState.coordinateToPixelTransform, coordinate.slice());\n    const data = this.hitRenderTarget_.readPixel(pixel[0] / 2, pixel[1] / 2);\n    const color = [data[0] / 255, data[1] / 255, data[2] / 255, data[3] / 255];\n    const index = colorDecodeId(color);\n    const opacity = this.renderInstructions_[index];\n    const uid = Math.floor(opacity).toString();\n    const source = this.getLayer().getSource();\n    const feature = source.getFeatureByUid(uid);\n    if (feature) {\n      return callback(feature, this.getLayer(), null);\n    }\n    return undefined;\n  }\n\n  /**\n   * Render the world, either to the main framebuffer or to the hit framebuffer\n   * @param {import(\"../../Map.js\").FrameState} frameState current frame state\n   * @param {boolean} forHitDetection whether the rendering is for hit detection\n   * @param {number} startWorld the world to render in the first iteration\n   * @param {number} endWorld the last world to render\n   * @param {number} worldWidth the width of the worlds being rendered\n   */\n  renderWorlds(frameState, forHitDetection, startWorld, endWorld, worldWidth) {\n    let world = startWorld;\n    this.helper.useProgram(this.program_, frameState);\n    if (forHitDetection) {\n      this.hitRenderTarget_.setSize([Math.floor(frameState.size[0] / 2), Math.floor(frameState.size[1] / 2)]);\n      this.helper.prepareDrawToRenderTarget(frameState, this.hitRenderTarget_, true);\n    }\n    this.helper.bindBuffer(this.verticesBuffer_);\n    this.helper.bindBuffer(this.indicesBuffer_);\n    this.helper.enableAttributes(this.attributes);\n    do {\n      this.helper.makeProjectionTransform(frameState, this.currentTransform_);\n      translateTransform(this.currentTransform_, world * worldWidth, 0);\n      multiplyTransform(this.currentTransform_, this.invertRenderTransform_);\n      this.helper.applyUniforms(frameState);\n      this.helper.applyHitDetectionUniform(forHitDetection);\n      const renderCount = this.indicesBuffer_.getSize();\n      this.helper.drawElements(0, renderCount);\n    } while (++world < endWorld);\n  }\n\n  /**\n   * Clean up.\n   */\n  disposeInternal() {\n    this.worker_.terminate();\n    this.layer_ = null;\n    this.sourceListenKeys_.forEach(function (key) {\n      unlistenByKey(key);\n    });\n    this.sourceListenKeys_ = null;\n    super.disposeInternal();\n  }\n  renderDeclutter() {}\n}\nexport default WebGLPointsLayerRenderer;","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}